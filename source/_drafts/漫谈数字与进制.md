---
title: 漫谈数字与进制
tags:
---


为什么要编码？ 比方 计算机 只理解英文 , 那么为了让计算机能理解其他国家的语言，就得经过一次翻译，这个翻译的过程就是编码

ascii 老美用计算机：大小写字母+数字+标点+控制字符 = 128 个字符搞定，字符占一个字节

eascii 发展到欧洲：利用剩余的1wei, 2^8 = 256

BIG5 中国港澳台用繁体：固定2个字节，收录13,060 个字符

GB2312 初到中国大陆：1个字节搞不定了，固定为 2个字节，理论支持 2^16 = 65536 理论支持，实际7445个字符，简体中文，不支持繁体

GBK  国标扩展：还是固长的2个字节，收录更多字包括繁体，再后来有 GB18030，变长 1或2或4个字节进行编码

国际组织想避免编码转换，搞个一统天下的编码
ISO/ICE-8859：一些列的8位字符集(还是一个字节咯)，考虑了西欧、中欧、泰语等等，可能是当时CJK网络不发达、计算机水平还不够，故没考虑进去，没有支持CJK的字符集

UTF-8：1-4个字节 动态长度表示，节省空间，asicc 1个；拉丁文、希腊文等等 2 个；大部分国家常用字 3个字节；极少使用的 4个字节进行编码
UTF-16：2或4个，大部分字符固长2字节，少部分4字节，因为只有2、4之分故不兼容ascii
UTF-32：固长4个，空间极大浪费

文件内容：茫茫一片不间断的二进制，该如何"断句"、根据对应字符集翻译，这就是字符编码所解决的问题。

### 字节序
字节序：字节间的顺序；超过8位（1个字节)如何排布的问题。

![alt](http://i.imgur.com/Y4GHzVH.png)

对于一个32位整数1，不同CPU架构会有不同的存储方式：
```
00000000 00000000 00000000 00000001  Big Endian: 最高有效位在最低有效位前面。大的(高有效位)在前端。
或
00000001 00000000 00000000 00000000  Little Endian: 最低有效位在最高有效位前面。小的(低有效位)在前端。
```

### `code point` 与 `code unit`
`code point`: 码点 ，一个码点可包括几个编码单元 ` @|_|@、@|_|-|_|@、@|_|-|_|-|_|@、@|_|-|_|-|_|-|_|@`

`code unit`: 编码单元，一个编码单元几个字节,  `|_._|` 延伸出码点：`@|_._|@`、`@|_._|-|_._|@`

码点 像词，读取一个词是不需要关注词的内部顺序的，

编码单元像一个字，读取多个字时 要知道是从左至右，还是从有至左 -高位到低位 、低位到高位

### `code point` 字符的码点之间为什么 没有顺序问题，另外是怎么确定起点码点位置 与结束码点位置？
1. 自然语言的分隔问题
    * "hello world" = “你好世界”  => 英文中间需要加空格，我们的中文中间不需要加空格。古代句与句之间甚至都没有，那时还没标点符号，所以有了所谓的**断句**，不同的断句法会有不同的意义。
```
民可使由之不可使知之 ——出自《论语 第八章 泰伯篇》

断法一：
民可使由之，不可使知之。
解释：你可以去驱使你的民众，但不可让他们知道为什么（不要去教他们知识）
评论：很显然是站在统治阶级立场的一种愚民论调。

断法二：
民可，使由之；不可，使知之。
解释：民众可以做的，放手让他们去做；不会做的，教会他们如何去做（又或：不可以去做的，让他们明白为何不可以）
评论：这看来是种不错的主张。
```    

编码的分隔：0和1表示了一切，在空格与标点都被数字化的情况下，我们怎么在这一串01中找出分隔来呢？ 显然我们需要外部约定。
> 8位(bit)一组的**字节**是最基本的一个约定，也是**文件**的基本单位，**文件就是字节的序列**。字节显然就是最基础的一个分隔依据。

文件的内容没有**暗示**它使用了何种编码，这就好比孔写下“民可使由之不可使知之”时并没有它是5|5分隔，还是2|3|2|3分隔那样的。

如何区分不同的定长(变长)编码方式？ 答案是**无法区分**。编码形成的字节带有特征，综合统计、语言偏好，可能**猜测**出正确的编码。 **编码信息与文件内容的分离，其实这正是乱码的根源**

定长编码：按固定的长度字节来编码。问题：定少了不够用，定多了浪费。

变长编码：不同长度字节编码字符。设计核心：如何区分不同的变长字节，只有这样才能在解码时不发生歧义。

### `java` 分割大文本文件，分别进行处理，怎么实现（不受不同编码影响）？


### 二进制显示字符太长，通常用16进制来表达
1个字符，最少占用用1个字节，最大占用4个字节，即二进制位：8-32 位，一个字符用二进制展示不管占1个还是4个字节都像一条长蛇，太过招摇。

`11111111` 或 `11111111 11111111 11111111 11111111` => `FF`或 `FF FF FF FF` 

### window 记事本 另存文件编码的误会
![文件另存为](http://wx2.sinaimg.cn/mw690/929194b4gy1fekthvz4s9j20rz05hglq.jpg)

在保存时可以选择ANSI、Unicode、Unicode big endian和UTF-8四种编码方式:

* 其中ANSI是默认的编码方式，对于英文文件是ASCII编码，对于简体中文文件是GB2312编码（windows简体中文版，如果是繁体中文版会采用Big5） ----- 误会1：把ANSI看出了 ASCII
* Unicode 其实是 UTF-16 Little endian编码方式，这个地方是微软将UTF-16 小端序称作Unicode而又不做详细说明。 --- 误会2
* Unicode big endian则是带有BOM的大端序编码方式

[深入分析 Java 中的中文编码问题](https://www.ibm.com/developerworks/cn/java/j-lo-chinesecoding/)

[国栋](http://xiaogd.net/)

计算机只认二进制：

                     -------> int: 32 位，其中最高1位为符号位，0正1负，故取值：+-2^31
                    |
二进制位 bit ---> byte-------> char:

基础：
    1 byte = 8 bit （二进制位）
    1 kb = 1024 byte (2^10 byte)

编码不同 字符char 与 字节byte 的转换则不同    
    ascii 编码： 固定占1个字节；char = 1 byte   , （ascii字符集 2^7 = 128 个字符，空1位，欧洲 eascii）

    UTF-8：占1~4个字节
    UTF-16：占2个 或 4个 字节
    UTF-32：固定占4个字节

    GB2312：固定占2个字节
    GBK：固定占2个字节

java:
    char = 2 byte = 16 bit



编码的原因总结：
1. 计算机存储信息的最小单元是一个字节即8个bit，所以能表示的字符范围是 0~255个
2. 人类要表示的符号太多，无法用一个字节完全表示
3. 要解决这个矛盾必须要一个新的数据结构`char`，从`char`到`byte`必须编码



生活中其他进制：
时间-时：12进制
    6点 + 7点 = 1点 （进位则是 am -> pm）
时间-分: 60进制
    50分 + 50分 = 1小时 + 40分
存储容量-M: 1024进制
    1024M = 1G


#### 数字
数字：`1001`
抽象分析：有已知： `位`、`位上的数值`  未知：`进制类型`

方法：位置 为指数，进制位底数 ，位上的数值为乘数

#### 小数
10进制 12.34 用 二进制表示
`12.34` = 1*10^1 + 2*10^0 + 3*(1/10) + 4*(1/100)
        = 1*10^1 + 3*10^-1 + 4*10^-2

酷睿会导致存储太长，常用高级表示类：
    8进制：

    16进制：
        每4位一组，成16进制
        故：一个字节 ----> 8个2进制位 ----> 2个16进制位
            一个字(双字节) ----> 16个2进制位 ----> 4个16进制位
        应用：html颜色：#F0F0F0、内存地址 0x00000251 等




### 位概念
`1001` 有 `4` 位， 不标明其进制，可以为任意进制的位，比如：2进制、8进制、10进制、16进制

参考：
* [bit、byte、位、字节、字符串等概念](http://www.cnblogs.com/tiantianle/p/5645338.html)
* [漫谈进制](http://www.cnblogs.com/supersumax/p/5882469.html)
* [有趣的二进制](https://my.oschina.net/u/1859679/blog/862744)



### 计算机中的概念
比特(bit)：比如 10根手指，就有 10个位    ===> binary digit(二进制位数)
字节(byte)：8个位组成一个 byte

### CPU 
晶体管 -通、断 - 01

### 字符 ‘1’ 与 数字 1 在内存中表示有和区别？
首先字符 '1' 是，字符对应有 字符编码，ascii : 49 ，`String.fromCharCode(49)`
数字1 不需要编码: 二进制：0001

### 计算机中 二进制怎样 表达 字符、字符串、声音、图像
* [字符集和字符编码（Charset & Encoding）](http://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html)

字符集：一个系统支持所有抽象字符的集合。字符是各种文字、符号、数字总称。 具体的字符集有：ASCII字符集、UNICODE字符集、GB2312字符集、BIG5字符集等

字符编码：一套法则，约定数字与符号的对应关系。


ascii : 8位一个字节(byte)来表示字符，有：[0-9]、[a-z]、[A-Z]、英式标点符号、终端特殊控制字符
```
    0-9  10    0011 0000 ~ 0011 1001
    a-z  26    0110 0001 ~ 0111 1010
    A-Z  26    0100 0001 ~ 0101 1010
标点字符  33    0010 0000 ~ 0010 1111
控制字符  33    0000 0000 ~ 0001 1111
```
10+26+26+33+33=128 表达完这些字符正好是: 2^7=128个，高位还空闲了1位，后来为了表示更多欧洲常用的字符，新的字符集`EASCII`使用了这1个位置，[0-127]保持的编码保持不变，不一样的是[128-255]这一段，即EASCII表达了255个字符

255 个字符在其他国家已经不足以表达了，汉子、日文、韩文等等(CJK)

GBXXX: 普通汉字字符集，占用2个字节，16个二进制位，[0-127]保持编码不变，两个大于127的的字符连在一起时，就表示一个汉字，前面一个字节(高位字节)[0xA1-0xF7]，后一个字节(低位字节)[0xA1-0xFE] 即可以组合出7000多个简体汉字了，把数学符号、希腊字符，ascii字符新编了双字节长的编码也就是全角符号。[(247-161)*(254-161)=7998]

BIG5：台湾、香港、澳门繁体字符集, 双八码存储方法，以两个字节来安放一个字,第一个字节称为"高位字节" [0x81-oxFE],第二个字节称为"低位字节"[0XA1-OXFE]

Unicode: 统一码，万国码，它使用4字节(2^8*2^4=2^32)表达任意语言的任意字符而设计 。(并不是所有的数字都用上了，但是总数已经超过了2^16-1=65535，所以2个字节的数字是不够用的)

Unicode是字符集，UTF-32/ UTF-16/ UTF-8是三种字符编码方案

    * UTF-32: 每个字符**都**使用4字节, 就空间而言，是非常没有效率的
    * UTF-16: 大多数人不会用到超过前65535个，UTF-16(因为16位 = 2字节)，如果真的需要表达那些很少使用的字符，则需要使用一些诡异的技巧来实现。规则
        1. 如果字符编码U小于0x10000，也就是十进制的0到65535之内，则直接使用两字节表示；
        2. 如果字符编码U大于0x10000，由于UNICODE编码范围最大为0x10FFFF，从0x10000到0x10FFFF之间 共有0xFFFFF个编码，也就是需要20个bit就可以标示这些编码。用U'表示从0-0xFFFFF之间的值，将其前 10 bit作为高位和16 bit的数值0xD800进行 逻辑or 操作，将后10 bit作为低位和0xDC00做 逻辑or 操作，这样组成的 4个byte就构成了U的编码。
    * UTF-8: （8-bit Unicode Transformation Format）是一种针对Unicode的可变长度字符编码（定长码），也是一种前缀码。
        如果一个字节，最高位（第 8 位）为 0，表示这是一个 ASCII 字符（00 - 7F）。可见，所有 ASCII 编码已经是 UTF-8 了。
        如果一个字节，以 11 开头，连续的 1 的个数暗示这个字符的字节数，例如：110xxxxx 代表它是双字节 UTF-8 字符的首字节。
        如果一个字节，以 10 开始，表示它不是首字节，需要向前查找才能得到当前字符的首字节


字符ascii: 49
      0001 1001 = 32 + 16 + 1
unicode: \u0031  = 3*16 +1 = 49 兼容ascii，是ascii的超集

* [二进制数据是如何变成图像和声音的](http://www.360doc.com/content/16/0813/07/29864439_582861943.shtml)

```
	0       0000
	1       0001
	2   	0010
	3   	0011
	4   	0100
	5   	0101
	6   	0110
	7   	0111
	8   	1000
	9   	1001
10	A   	1010
11	B   	1011
12	C   	1100
13	D   	1101
14	E   	1110 
15	F   	1111

一般2进制 ====》 16进制

   1101 1001 1011 1001
ox  D   9    B    9 
    D   9    B    9    H


带小数时，小数两端补0，让数字位数凑足4的倍数

       1 0111.011
=> 00001 0111.0110
ox   1    7  .  6


一般16进制 ====》 2进制
0x17.6

=>  	0	1	7     .	6
               0001    0111   . 0110

16进制 ===> 10进制
0x2AF5

	2	A	F	5
      2*16^3  10*16^2  15*16^1  5
      2*4096    10*256  15*16   5

16^1 = 2 ^ 4 = 16
16^2 = (2^4)*(2^4) = 2^8 = 256
16^3 = (2^4)*(2^4)*(2^4) = 2^12 = 4096

log2 ^16 = 4

幂（power）指乘方运算的结果，n^m指将n自乘m次,把n^m看作乘方的结果,叫做n的m次幂.

指数：在乘方a^n中,其中的a叫做底数,n叫做指数,结果叫幂,读“mì”

法则口诀
同底数幂的乘法：底数不变，指数相加幂的乘方；
同底数幂的除法：底数不变，指数相减幂的乘方；
幂的指数乘方：等于各因数分别乘方的积商的乘方
分式乘方：分子分母分别乘方，指数不变。




位运算程序优化应用：http://blog.csdn.net/zmazon/article/details/8262185
```




### ECMAScript的 位操作
ECMAScript 数值使用IEEE-754 64位格式存储，但位操作不能操作64位的值，而是将64位的值转换成32位的整数，然后进行操作，再转回64位

对于有符号的整数，32位中的小端31位表示整数的值，第32位表示数值的符号，0表示整数，1表示负数，这个位叫做符号位。

负数的二进制表示：取负数绝对值，列二进制序列表示；取反码(按位非 ~)；反码加1

```
位操作符：
    按位与(& AND)  : 用法 a & b;    两个操作数对应bit位，都为1，则为1，否则为0
    按位或(| OR)   ：用法 a | b;    两个操作数对应bit位，存在一位为1，则为1，否则为0
    按位亦或(^ XOR)：用法 a ^ b;    两个操作数对应bit位，只有一位为1，则为1，否则为0
    按位非(~ NOT)  ：用法 ~a;       反转操作数的bit位，0变1，1变0

    左移(<<)   　  ：用法 a << b; 将a的二进制序列向左移b(<32)位，右边用0补充
    有符号右移(>>)  ：用法 a >> b; 将a的二进制序列向右移b(<32)位，丢弃被移除的位 -- 符号位保留，数值序列往右移位，左侧空位以符号位填充
    无符号右移(>>>)  ：用法 a >>> b; 将a的二进制序列向右移b(<32)位，丢弃被移除的位，并且用0在左侧填充 -- 整个数值序列往右移位，左侧空位以0填充
```